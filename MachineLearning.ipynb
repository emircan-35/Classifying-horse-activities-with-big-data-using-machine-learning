{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09cd650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def machine_learning(data,name):\n",
    "    print(\"G. Boosting - Accuracy \",end='')\n",
    "    G_Boosting(data,name)\n",
    "    print()\n",
    "\n",
    "    print(\"XgBoost - Accuracy \",end='')\n",
    "    XgBoost(data,name)\n",
    "    print()\n",
    "    print(\"Light G. Boosting - Accuracy \",end='')\n",
    "    lightG_Boosting(data,name)\n",
    "    print()\n",
    "    print(\"random forest - Accuracy \",end='')\n",
    "    randomForest(data,name)\n",
    "    print()\n",
    "    \n",
    "\n",
    "\n",
    "    print(\"Extra Trees - Accuracy \",end='')\n",
    "    extra_trees(data,name)\n",
    "    print()\n",
    "\n",
    "    print(\"Bagging Trees  - Accuracy \",end='')\n",
    "    bagging_trees(data,name)\n",
    "    print()\n",
    "\n",
    "    print(\"ada boost - Accuracy \",end='')\n",
    "    ada_boost(data,name)\n",
    "    print()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    print(\"Cat Boosting - Accuracy \",end='')\n",
    "    cat_Boost(data,name)\n",
    "    print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef2c62cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(data,name):\n",
    "    x = data.iloc[:,0:51] \n",
    "    y = data.iloc[:,52:53]\n",
    "    cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    # create model\n",
    "    model = RandomForestClassifier(random_state=1)\n",
    "    y_pred = cross_val_predict(model, x, y.values.ravel(), cv=10)\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    print(metrics.accuracy_score(y.values.ravel(), y_pred))\n",
    "    print(\"\\nprecision | macro -->    \",precision_score(y, y_pred, average='macro'))\n",
    "    print(\"precision | micro -->    \",precision_score(y, y_pred, average='micro'))\n",
    "    print(\"precision | weighted --> \",precision_score(y, y_pred, average='weighted'))\n",
    "    print(\"recall | macro -->       \",recall_score(y, y_pred, average='macro')  )\n",
    "    print(\"recall | micro -->       \",recall_score(y, y_pred, average='micro')  )\n",
    "    print(\"recall | weighted -->    \",recall_score(y, y_pred, average='weighted')  )\n",
    "    print(\"F1 | macro -->           \",f1_score(y, y_pred, average='macro'))\n",
    "    print(\"F1 | micro -->           \",f1_score(y, y_pred, average='micro'))\n",
    "    print(\"F1 | weighted -->           \",f1_score(y, y_pred, average='weighted'))\n",
    "    print(conf_mat)\n",
    "    conf_mat=100*conf_mat\n",
    "\n",
    "    save_matrix(conf_mat,name+\"RandomForest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "456a7b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada_boost(data,name):\n",
    "    x = data.iloc[:,0:51] \n",
    "    y = data.iloc[:,52:53]\n",
    "    model = AdaBoostClassifier()\n",
    "    y_pred = cross_val_predict(model, x.values, y.values.ravel(), cv=10)\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "    print(metrics.accuracy_score(y.values.ravel(), y_pred))\n",
    "    print(\"\\nprecision | macro -->    \",precision_score(y, y_pred, average='macro'))\n",
    "    print(\"precision | micro -->    \",precision_score(y, y_pred, average='micro'))\n",
    "    print(\"precision | weighted --> \",precision_score(y, y_pred, average='weighted'))\n",
    "    print(\"recall | macro -->       \",recall_score(y, y_pred, average='macro')  )\n",
    "    print(\"recall | micro -->       \",recall_score(y, y_pred, average='micro')  )\n",
    "    print(\"recall | weighted -->    \",recall_score(y, y_pred, average='weighted')  )\n",
    "    print(\"F1 | macro -->           \",f1_score(y, y_pred, average='macro'))\n",
    "    print(\"F1 | micro -->           \",f1_score(y, y_pred, average='micro'))\n",
    "    print(\"F1 | weighted -->           \",f1_score(y, y_pred, average='weighted'))\n",
    "    print(conf_mat)\n",
    "    conf_mat=100*conf_mat\n",
    "\n",
    "    save_matrix(conf_mat,name+\"AdaBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03cac4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XgBoost(data,name):\n",
    "    x = data.iloc[:,0:51] \n",
    "    y = data.iloc[:,52:53]\n",
    "    model = XGBClassifier(use_label_encoder=False,eval_metric='mlogloss')\n",
    "    y_pred = cross_val_predict(model, x, y.values.ravel(), cv=10)\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    print(metrics.accuracy_score(y.values.ravel(), y_pred))\n",
    "    print(\"\\nprecision | macro -->    \",precision_score(y, y_pred, average='macro'))\n",
    "    print(\"precision | micro -->    \",precision_score(y, y_pred, average='micro'))\n",
    "    print(\"precision | weighted --> \",precision_score(y, y_pred, average='weighted'))\n",
    "    print(\"recall | macro -->       \",recall_score(y, y_pred, average='macro')  )\n",
    "    print(\"recall | micro -->       \",recall_score(y, y_pred, average='micro')  )\n",
    "    print(\"recall | weighted -->    \",recall_score(y, y_pred, average='weighted')  )\n",
    "    print(\"F1 | macro -->           \",f1_score(y, y_pred, average='macro'))\n",
    "    print(\"F1 | micro -->           \",f1_score(y, y_pred, average='micro'))\n",
    "    print(\"F1 | weighted -->           \",f1_score(y, y_pred, average='weighted'))\n",
    "    conf_mat=100*conf_mat\n",
    "    save_matrix(conf_mat,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67397117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_trees(data,name):\n",
    "    x = data.iloc[:,0:51] \n",
    "    y = data.iloc[:,52:53]\n",
    "    model = ExtraTreesClassifier()\n",
    "    y_pred = cross_val_predict(model, x, y.values.ravel(), cv=10)\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    print(metrics.accuracy_score(y.values.ravel(), y_pred))\n",
    "    print(\"\\nprecision | macro -->    \",precision_score(y, y_pred, average='macro'))\n",
    "    print(\"precision | micro -->    \",precision_score(y, y_pred, average='micro'))\n",
    "    print(\"precision | weighted --> \",precision_score(y, y_pred, average='weighted'))\n",
    "    print(\"recall | macro -->       \",recall_score(y, y_pred, average='macro')  )\n",
    "    print(\"recall | micro -->       \",recall_score(y, y_pred, average='micro')  )\n",
    "    print(\"recall | weighted -->    \",recall_score(y, y_pred, average='weighted')  )\n",
    "    print(\"F1 | macro -->           \",f1_score(y, y_pred, average='macro'))\n",
    "    print(\"F1 | micro -->           \",f1_score(y, y_pred, average='micro'))\n",
    "    print(\"F1 | weighted -->           \",f1_score(y, y_pred, average='weighted'))\n",
    "    print(conf_mat)\n",
    "    conf_mat=100*conf_mat\n",
    "\n",
    "    save_matrix(conf_mat,name+\"ExtraTrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb03657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_trees(data,name):\n",
    "    x = data.iloc[:,0:51] \n",
    "    y = data.iloc[:,52:53]\n",
    "    model = BaggingClassifier()\n",
    "    y_pred = cross_val_predict(model, x, y.values.ravel(), cv=10)\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    print(metrics.accuracy_score(y.values.ravel(), y_pred))\n",
    "    print(\"\\nprecision | macro -->    \",precision_score(y, y_pred, average='macro'))\n",
    "    print(\"precision | micro -->    \",precision_score(y, y_pred, average='micro'))\n",
    "    print(\"precision | weighted --> \",precision_score(y, y_pred, average='weighted'))\n",
    "    print(\"recall | macro -->       \",recall_score(y, y_pred, average='macro')  )\n",
    "    print(\"recall | micro -->       \",recall_score(y, y_pred, average='micro')  )\n",
    "    print(\"recall | weighted -->    \",recall_score(y, y_pred, average='weighted')  )\n",
    "    print(\"F1 | macro -->           \",f1_score(y, y_pred, average='macro'))\n",
    "    print(\"F1 | micro -->           \",f1_score(y, y_pred, average='micro'))\n",
    "    print(\"F1 | weighted -->           \",f1_score(y, y_pred, average='weighted'))\n",
    "    print(conf_mat)\n",
    "    conf_mat=100*conf_mat\n",
    "\n",
    "    save_matrix(conf_mat,name+\"BaggingTrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd674bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightG_Boosting(data,name):\n",
    "    x = data.iloc[:,0:51] \n",
    "    y = data.iloc[:,52:53]\n",
    "    model = LGBMClassifier()\n",
    "    y_pred = cross_val_predict(model, x, y.values.ravel(), cv=10)\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    print(metrics.accuracy_score(y.values.ravel(), y_pred))\n",
    "    print(\"\\nprecision | macro -->    \",precision_score(y, y_pred, average='macro'))\n",
    "    print(\"precision | micro -->    \",precision_score(y, y_pred, average='micro'))\n",
    "    print(\"precision | weighted --> \",precision_score(y, y_pred, average='weighted'))\n",
    "    print(\"recall | macro -->       \",recall_score(y, y_pred, average='macro')  )\n",
    "    print(\"recall | micro -->       \",recall_score(y, y_pred, average='micro')  )\n",
    "    print(\"recall | weighted -->    \",recall_score(y, y_pred, average='weighted')  )\n",
    "    print(\"F1 | macro -->           \",f1_score(y, y_pred, average='macro'))\n",
    "    print(\"F1 | micro -->           \",f1_score(y, y_pred, average='micro'))\n",
    "    print(\"F1 | weighted -->           \",f1_score(y, y_pred, average='weighted'))\n",
    "    print(conf_mat)\n",
    "    conf_mat=100*conf_mat\n",
    "\n",
    "    save_matrix(conf_mat,name+\"LightGBoosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37005654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def G_Boosting(data,name):\n",
    "    x = data.iloc[:,0:51] \n",
    "    y = data.iloc[:,52:53]\n",
    "    model = GradientBoostingClassifier()\n",
    "    y_pred = cross_val_predict(model, x, y.values.ravel(), cv=10)\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    print(metrics.accuracy_score(y.values.ravel(), y_pred))\n",
    "    print(\"\\nprecision | macro -->    \",precision_score(y, y_pred, average='macro'))\n",
    "    print(\"precision | micro -->    \",precision_score(y, y_pred, average='micro'))\n",
    "    print(\"precision | weighted --> \",precision_score(y, y_pred, average='weighted'))\n",
    "    print(\"recall | macro -->       \",recall_score(y, y_pred, average='macro')  )\n",
    "    print(\"recall | micro -->       \",recall_score(y, y_pred, average='micro')  )\n",
    "    print(\"recall | weighted -->    \",recall_score(y, y_pred, average='weighted')  )\n",
    "    print(\"F1 | macro -->           \",f1_score(y, y_pred, average='macro'))\n",
    "    print(\"F1 | micro -->           \",f1_score(y, y_pred, average='micro'))\n",
    "    print(\"F1 | weighted -->           \",f1_score(y, y_pred, average='weighted'))\n",
    "    print(conf_mat)\n",
    "    conf_mat=100*conf_mat\n",
    "\n",
    "    save_matrix(conf_mat,name+\"GBoosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52d61337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_Boost(data,name):\n",
    "    x = data.iloc[:,0:51] \n",
    "    y = data.iloc[:,52:53]\n",
    "    model = CatBoostClassifier(verbose=0, n_estimators=100)\n",
    "    y_pred = cross_val_predict(model, x, y.values.ravel(), cv=10)\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    print(metrics.accuracy_score(y.values.ravel(), y_pred))\n",
    "    print(\"\\nprecision | macro -->    \",precision_score(y, y_pred, average='macro'))\n",
    "    print(\"precision | micro -->    \",precision_score(y, y_pred, average='micro'))\n",
    "    print(\"precision | weighted --> \",precision_score(y, y_pred, average='weighted'))\n",
    "    print(\"recall | macro -->       \",recall_score(y, y_pred, average='macro')  )\n",
    "    print(\"recall | micro -->       \",recall_score(y, y_pred, average='micro')  )\n",
    "    print(\"recall | weighted -->    \",recall_score(y, y_pred, average='weighted')  )\n",
    "    print(\"F1 | macro -->           \",f1_score(y, y_pred, average='macro'))\n",
    "    print(\"F1 | micro -->           \",f1_score(y, y_pred, average='micro'))\n",
    "    print(\"F1 | weighted -->           \",f1_score(y, y_pred, average='weighted'))\n",
    "    print(conf_mat)\n",
    "    conf_mat=100*conf_mat\n",
    "\n",
    "    save_matrix(conf_mat,name+\"CatBoosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d26eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_matrix(conf_mat,name):\n",
    "    df_cfm = pd.DataFrame(conf_mat)\n",
    "    sn.set_theme(font='Calibri',font_scale=7)\n",
    "    LABELS=['galloping','standing','trotting','walking','grazing']\n",
    "    df_cfm=df_cfm.round(decimals=2)\n",
    "    plt.figure(figsize=(36, 24))\n",
    "\n",
    "    sn.heatmap(df_cfm,\n",
    "                cmap='Blues',\n",
    "                linecolor='white',\n",
    "                linewidths=1,\n",
    "                xticklabels=LABELS,\n",
    "                yticklabels=LABELS,\n",
    "                annot=True,\n",
    "                fmt = \".2f\")\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    plt.title('Confusion Matrix',fontname=\"Calibri\",fontweight=\"bold\")\n",
    "    plt.ylabel('Actual',fontname=\"Calibri\",fontweight=\"bold\")\n",
    "    plt.xlabel('Predicted',fontname=\"Calibri\",fontweight=\"bold\")\n",
    "    plt.savefig(name+\".png\",dpi=600,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff664ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_per_subject_extraTrees(statistics):\n",
    "    total_x=pd.DataFrame()\n",
    "    total_yFrame=[]\n",
    "    total_y_predicted=[]\n",
    "    for statistic in statistics:\n",
    "        if statistic==\"All.csv\":\n",
    "            continue\n",
    "        print(statistic)\n",
    "        x = statistics[statistic].iloc[:,0:51] \n",
    "        y = statistics[statistic].iloc[:,52:53]\n",
    "        print(x.shape)\n",
    "        print(y.shape)\n",
    "        model = ExtraTreesClassifier()\n",
    "        y_pred = cross_val_predict(model, x, y.values.ravel(), cv=10)\n",
    "        print(y_pred.shape)\n",
    "        total_x=total_x+x\n",
    "        total_yFrame.append(y)\n",
    "        total_y_predicted=total_y_predicted+y_pred.tolist()\n",
    "        \n",
    "    total_y=pd.concat(total_yFrame)\n",
    "    total_y_predicted=np.array(total_y_predicted)\n",
    "    \n",
    "    conf_mat = confusion_matrix(total_y, total_y_predicted)\n",
    "    conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "    print(\"Merged 6 subject for Extra Trees model, accurac --> \",end='')\n",
    "    print(metrics.accuracy_score(total_y.values.ravel(), total_y_predicted))\n",
    "    print(\"\\nprecision | macro -->    \",precision_score(total_y, total_y_predicted, average='macro'))\n",
    "    print(\"precision | micro -->    \",precision_score(total_y, total_y_predicted, average='micro'))\n",
    "    print(\"precision | weighted --> \",precision_score(total_y, total_y_predicted, average='weighted'))\n",
    "    print(\"recall | macro -->       \",recall_score(total_y, total_y_predicted, average='macro')  )\n",
    "    print(\"recall | micro -->       \",recall_score(total_y, total_y_predicted, average='micro')  )\n",
    "    print(\"recall | weighted -->    \",recall_score(total_y, total_y_predicted, average='weighted')  )\n",
    "    print(\"F1 | macro -->           \",f1_score(total_y, total_y_predicted, average='macro'))\n",
    "    print(\"F1 | micro -->           \",f1_score(total_y, total_y_predicted, average='micro'))\n",
    "    print(\"F1 | weighted -->           \",f1_score(total_y, total_y_predicted, average='weighted'))\n",
    "    save_matrix(conf_mat,\"per_subject_extra_trees\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b36c443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_conf_matrixes_per_subject_extraTrees(statistics):\n",
    "    conf_matrixes=[]\n",
    "    for statistic in statistics:\n",
    "        if statistic==\"All.csv\":\n",
    "            continue\n",
    "        x = statistics[statistic].iloc[:,0:51] \n",
    "        y = statistics[statistic].iloc[:,52:53]\n",
    "        model = ExtraTreesClassifier()\n",
    "        y_pred = cross_val_predict(model, x, y.values.ravel(), cv=10)\n",
    "        conf_mat = confusion_matrix(y, y_pred)\n",
    "        conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "        conf_matrixes.append(conf_mat*100)\n",
    "        \n",
    "    \n",
    "    conf_mat=np.mean(np.array(conf_matrixes), axis=0 )\n",
    "    save_matrix(conf_mat,\"merged_conf_matrix_per_subject_extra_trees\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be2ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
