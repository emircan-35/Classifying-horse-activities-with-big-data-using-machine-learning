{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e98cc1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from scipy import signal\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn,optim\n",
    "from torch.nn import functional as F\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import seaborn as sn\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import np_utils\n",
    "from scipy.stats import norm,kurtosis,skew\n",
    "import antropy as ant\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "217a0347",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# All variables releated with data are located here to make an order\n",
    "###\n",
    "le=preprocessing.LabelEncoder()\n",
    "LABELS=['running','standing','trotting','walking','grazing-eating']\n",
    "PATH=\"C:\\\\Users\\\\emirc\\\\Desktop\\\\AAR\\\\dataHandled/*\" #Refer the path having the csv files\n",
    "OUTPUT_LABEL='ActivityEncoded'\n",
    "\n",
    "REMOVE_COLUMNS=['Mx','My','Mz','Gx','Gy','Gz','G3D','M3D','A3D','segment'] #Columns to delete such as Gx Gy Gz\n",
    "SUBJECTS=['Happy','Zafir','Drieku','Galoway','Patron','Bacardi']\n",
    "TIME_PERIODS = 200\n",
    "STEP_DISTANCE = 100\n",
    "FILES = sorted(glob.glob(PATH))\n",
    "N_FEATURES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e11334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_activities(df):\n",
    "    df['label']=df['label'].replace(to_replace=['trotting-natural'], value='trotting')\n",
    "    df['label']=df['label'].replace(to_replace=['trotting-rider'], value='trotting')\n",
    "    df['label']=df['label'].replace(to_replace=['galloping-rider'], value='running')\n",
    "    df['label']=df['label'].replace(to_replace=['galloping-natural'], value='running')\n",
    "    df['label']=df['label'].replace(to_replace=['walking-rider'], value='walking')\n",
    "    df['label']=df['label'].replace(to_replace=['walking-natural'], value='walking')\n",
    "    df['label']=df['label'].replace(to_replace=['grazing'], value='grazing-eating')\n",
    "    df['label']=df['label'].replace(to_replace=['eating'], value='grazing-eating')\n",
    "    result=df[df['label'].isin(LABELS)]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bba0f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataFrames():\n",
    "    for subject in SUBJECTS:\n",
    "        files=[]\n",
    "        for file in FILES:\n",
    "            if subject in file:\n",
    "                files.append(file)\n",
    "        df=pd.DataFrame()\n",
    "        for file in files:\n",
    "            csv=pd.read_csv(file,low_memory=False)\n",
    "            df=df.append(csv)\n",
    "            \n",
    "        df.drop(REMOVE_COLUMNS, axis=1, inplace=True)\n",
    "        df=df.dropna()\n",
    "        df=merge_activities(df)\n",
    "        df[OUTPUT_LABEL]=le.fit_transform(df['label'].values.ravel())\n",
    "        df.to_csv('C:\\\\Users\\\\emirc\\\\Desktop\\\\AAR\\\\codes\\\\dataHandled\\\\'+subject+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "49f67fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCleanCSV():\n",
    "    df=pd.DataFrame()   \n",
    "    for file in FILES:\n",
    "        csv=pd.read_csv(file,low_memory=False)\n",
    "        df=df.append(csv)\n",
    "    \n",
    "    df.drop(REMOVE_COLUMNS, axis=1, inplace=True)\n",
    "    df=df.dropna()\n",
    "    df=merge_activities(df)\n",
    "    df[OUTPUT_LABEL]=le.fit_transform(df['label'].values.ravel())\n",
    "    df.to_csv('C:\\\\Users\\\\emirc\\\\Desktop\\\\AAR\\\\codes\\\\dataHandled\\\\all.csv',index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "692c7d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCSV(path, name):\n",
    "    df=pd.DataFrame()\n",
    "    csv=pd.read_csv(path+name+'.csv')\n",
    "    df=df.append(csv)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
